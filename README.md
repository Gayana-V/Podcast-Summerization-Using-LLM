<<<<<<< HEAD
# Podcast-Summerization-Using-LLM
Podcast Summerization using llm with hoard diarization website
=======
# PodSummarize

PodSummarize is a full-stack web application that ingests podcast episodes, performs transcription and speaker diarization, and generates structured summaries powered by a Large Language Model (LLM). It optionally delivers an audio version of the summary via text-to-speech (TTS) and exposes a responsive UI for reviewing results.

![PodSummarize Logo](assets/logo.svg)

## Features

- Upload MP3 / WAV audio or provide a public podcast URL.
- Track processing in real time across upload, transcription, diarization, summarization, and TTS stages.
- Review diarized transcripts with speaker turns and timestamps.
- Receive per-speaker highlights and an overall episode synopsis generated by GPT-4–class LLMs.
- Listen to the original audio and synthesized summary audio (when TTS is enabled).
- Download or share transcripts and summaries.
- Mobile-first, responsive React UI.

## Architecture

| Layer       | Technology | Notes |
|-------------|------------|-------|
| Frontend    | React 18 + TypeScript + Vite | REST integration, responsive layouts, status polling |
| Backend     | FastAPI (Python 3.11)        | Endpoints for upload, processing, results, TTS |
| Transcription | OpenAI Whisper (primary) with AssemblyAI / Google STT fallbacks | Configure via environment |
| Diarization | [Hoard](https://github.com/hoard-ai/hoard) framework | Converts transcripts into speaker-aware segments |
| Summarization | OpenAI GPT-4o-mini (default), Google Gemini, or DeepSeek | Structured JSON summary prompt |
| TTS (optional) | Azure Speech (default), Google TTS, or Coqui | Produces summary audio |

Processing is orchestrated asynchronously within the backend service, with in-memory job state (sufficient for demos). Each stage writes artifacts to `storage/results/<job_id>/`.

## Quick Start

### Prerequisites

- Python 3.11+
- Node.js 20+
- Docker (optional, for containers)
- FFmpeg (installed automatically in the backend container)

### 1. Clone & Install

```bash
git clone https://github.com/your-org/podsummarize.git
cd podsummarize
```

Copy environment templates and fill in secrets:

```bash
cp env.example .env        # or set environment variables manually
cp frontend/env.example frontend/.env
```

Set `LLM_PROVIDER` to `gemini` and supply `GEMINI_API_KEY` when using Google Gemini models (e.g., `gemini-1.5-flash-latest`).

#### Backend

```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

> **Optional (Hoard diarization)**  
> The pipeline automatically falls back to a simple speaker alternation when the Hoard library is unavailable.  
> If you do have access to Hoard, install it separately after the requirements step:  
> `pip install git+https://github.com/hoard-ai/hoard.git`

#### Frontend

```bash
cd frontend
npm install
npm run dev
```

Open <http://localhost:5173>.

### 2. Docker Compose

Build and launch production-ready containers:

```bash
cd docker
docker compose up --build
```

Frontend: <http://localhost:5173>  
Backend API: <http://localhost:8000>

## Backend Overview

Key modules are in `backend/app`:

| File | Description |
|------|-------------|
| `main.py` | FastAPI application defining REST endpoints. |
| `services/transcription.py` | Whisper (and fallback) transcription logic. |
| `services/diarization.py` | Hoard-based diarization (`HoardDiarizer.run`). |
| `services/llm.py` | LLM prompt execution with structured JSON output. |
| `services/tts.py` | TTS integrations (Azure by default). |
| `services/pipeline.py` | Orchestrates the processing flow and job status. |
| `models.py` | Pydantic models for requests, responses, and job state. |
| `config.py` | Environment-driven configuration. |

### API Endpoints

| Method | Endpoint | Purpose |
|--------|----------|---------|
| `POST /upload` | Upload audio or submit a podcast URL. returns `job_id`. |
| `POST /process` | Start processing pipeline (transcription → diarization → summary → TTS). |
| `GET /results/{job_id}` | Retrieve status, transcript, summary, and asset URLs. |
| `POST /tts` | Generate TTS for arbitrary text (used to refresh summary audio). |
| `GET /media/{job_id}/{filename}` | Download stored assets (audio, transcript, summary). |
| `GET /health` | Health check. |

### Integration Notes

- **Whisper invocation**: See `services/transcription.py`, `_transcribe_with_whisper` for the exact API call.
- **Hoard diarization**: `services/diarization.py` shows how `HoardDiarizer` is initialized and invoked. A fallback assigns speakers when Hoard is unavailable.
- **LLM prompting**: `services/llm.py` includes the prompt string `"Summarize this transcript, giving per-speaker highlights and overall episode summary"` and converts transcripts into structured summary JSON across OpenAI, Gemini, or DeepSeek providers.
- **TTS synthesis**: `services/tts.py` contains Azure Speech integration; placeholders for Google and Coqui are supplied for future extension.

Errors at each stage update the job state to `failed` and are relayed to the UI.

## Frontend Overview

Routes are declared in `src/App.tsx`:

- `/` – Upload form (`HomePage`).
- `/status/:jobId` – Live pipeline status with polling (`StatusPage`).
- `/results/:jobId` – Transcript, summary, and audio players (`ResultsPage`).

Reusable helpers live in:

- `src/api/` – Axios client and REST wrappers.
- `src/types.ts` – Shared TypeScript definitions aligned with backend models.
- `src/index.css` – Minimal design system.

The status page polls `/results/{job_id}` until completion and automatically routes to the results page. Errors surface inline with helpful guidance.

## Sample Data

The `sample_data/` directory provides example JSON artifacts. Download a short, license-free clip (e.g., [Pixabay Podcast Sample](https://cdn.pixabay.com/download/audio/2023/03/01/audio_5f6e7fa7d0.mp3?filename=podcast-intro-141318.mp3)) and save it as `sample_data/sample_episode.mp3`. You can then upload it through the UI or cURL:

```bash
curl -F "file=@sample_data/sample_episode.mp3" http://localhost:8000/upload
```

Mock transcript/summary JSON files help in testing the frontend without executing the full pipeline.

## Testing & Quality

- **Backend**: Run `uvicorn` locally and test endpoints via `curl` or Postman. Add unit tests with `pytest` for production usage.
- **Frontend**: `npm run lint` ensures TypeScript + React linting. Extend with `vitest` for UI unit tests.
- **Manual QA**: Confirm diarization labels, summary coherence, and TTS audio playback. Validate error states by omitting API keys.

## Deployment Notes

- Provide environment secrets to containers (e.g., via Docker secrets or orchestrator-managed env vars).
- For persistence, mount `storage/` to durable disks (S3, Azure Blob, etc.).
- Production deployments should replace the in-memory job tracker with Redis or a database plus task queue.
- Ensure HTTPS termination and restrict CORS origins.

## License

This project is provided as-is for demonstration purposes. Ensure compliance with the licenses of Whisper, Hoard, and any third-party services before deploying commercially.


>>>>>>> bd7ffbf (added all the working files)
